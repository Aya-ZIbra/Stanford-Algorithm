**THE MASTER METHOD** \- These lectures cover a "black\-box" method for solving recurrences. You can then immediately determine the running time of most of the divide\-and\-conquer algorithms that you'll ever see! (Including Karatsuba's integer multiplication algorithm and Strassen's matrix multiplication algorithm from Week 1.) The proof is a nice generalization of the recursion tree method that we used to analyze MergeSort. Ever wonder about the mysterious three cases of the Master Method? Watch these videos and hopefully all will become clear.

**QUICKSORT \- THE ALGORITHM** \- One of the greatest algorithms ever, and our first example of a randomized algorithm. These lectures go over the pseudocode \-\-\- the high\-level approach, how to partition an array around a pivot element in linear time with minimal extra storage, and the ramifications of different pivot choices \-\-\- and explain how the algorithm works.

**QUICKSORT \- THE ANALYSIS** \-These lectures are optional, but I strongly encourage you to watch them if you have time. They prove that randomized QuickSort (i.e., with random pivot choices) runs in O(n log n) time on average. The analysis is as elegant as the algorithm itself, and is based on a "decomposition principle" that is often useful in the analysis of randomized algorithms. Note that there are some accompanying lectures notes for this part (available for download underneath each video).

**PROBABILITY REVIEW** \- This first of these optional lecture videos reviews the concepts from discrete probability that are necessary for the QuickSort analysis \-\-\- sample spaces, events, random variables, expectation, and linearity of expectation. The second video covers just two topics, although quite tricky ones! (Namely, conditional probability and independence.) You need to review this material (via this video or some other source, as you wish) before studying the analysis of the randomized contraction algorithm in Week 3.

**HOMEWORK**: Problem Set #2 has five questions that should give you practice with the Master Method and help you understand QuickSort more deeply. Programming Assignment #2 asks you to implement QuickSort and compute the number of comparisons that it makes for three different pivot rules.

**RELATED READINGS:** *[Algorithms Illuminated (Part 1)](https://www.amazon.com/dp/0999282905)*, Chapters 4 and 5.

**Optional Theoretical Problems:** 
1\. Give the best upper bound that you can on the solution to the following recurrence: T(1)\=1 and T(n)≤T(\[n\])+1 for n\>1. (Here \[x\] denotes the "floor" function, which rounds down to the nearest integer.)

2\. You are given an n by n grid of distinct numbers. A number is a local minimum if it is smaller than all of its neighbors. (A neighbor of a number is one immediately above, below, to the left, or the right. Most numbers have four neighbors; numbers on the side have three; the four corners have two.) Use the divide\-and\-conquer algorithm design paradigm to compute a local minimum with only O(n) comparisons between pairs of numbers. (Note: since there are n2 numbers in the input, you cannot afford to look at all of them. Hint: Think about what types of recurrences would give you the desired upper bound.)

**Linear\-Time Selection \- **These lectures study the problem of computing the ith smallest element of an input array (e.g., the median). It's easy to solve this problem in O(n log n) time using sorting, but we can do better! The required material goes over a super\-practical randomized algorithm, very much in the spirit of QuickSort, that has \*linear\* expected running time. Don't forget that it takes linear time just to read the input! The analysis is somewhat different than what we studied for QuickSort, but is equally slick. Basically, there's a cool way to think about the progress the algorithm makes in terms of a simple coin\-flipping experiment. Linearity of expectation (yes, it's back...) seals the deal.

**Linear\-Time Selection** (Optional) **\-** I couldn't resist covering some advanced related material. The first is an algorithm that has more Turing Award\-winning authors than any other algorithm that I know of. It is a deterministic (i.e., no randomization allowed) linear\-time algorithm for the Selection problem, based on an ingenious "median\-of\-medians" idea for guaranteeing good pivot choices. (There are some accompanying lectures notes for this part, available for download underneath each video.) The second optional topic answers the question "can we do better?" for sorting, unfortunately in the negative. That is, a counting argument shows that there is no "comparison\-based" sorting algorithm (like MergeSort, QuickSort, or HeapSort) with worst\-case running time better than n log n.

**Graphs and the Contraction Algorithm \-** The second set of lectures for this week is a segue from randomized algorithms to graph algorithms. We first review graphs and the most standard ways of representing them (most commonly, by adjacency lists). We then consider the random contraction algorithm, discovered by Karger "only" 20ish years ago (while a PhD student here at Stanford). This algorithm solves the minimum cut problem \-\-\- given an undirected graph, separate the vertices into two non\-empty groups to minimize the number of "crossing edges". Such problems come up when reasoning about, for example, physical networks, social networks, and images. This algorithm was perhaps the first strong evidence that graph problems could be added to the long list of "killer applications" of random sampling. Don't tune out before the final plot twist \-\-\- a simple but useful trick for transforming an algorithm that almost always fails into one that almost always succeeds.

**HOMEWORK**: Problem Set #3 has five questions about the randomized selection algorithm, cuts in graphs, and the contraction algorithm. Programming Assignment #3 asks you to implement the contraction algorithm and use it to compute the min cut of the graph that we provide.

**RELATED READINGS:** *[Algorithms Illuminated (Part 1)](https://www.amazon.com/dp/0999282905)*, Chapter 6.


* [Sign in or Register | Stanford Lagunita](https://lagunita.stanford.edu/login?next=/courses/course-v1%3AEngineering%2BAlgorithms1%2BSelfPaced/course/)
* [Sign in or Register | Stanford Lagunita](https://lagunita.stanford.edu/login?next=/courses/course-v1%3AEngineering%2BAlgorithms1%2BSelfPaced/courseware/2cb01d3fab0e41c5b97a4658d8d1bbfd/fe413b3a7c1447288a9a631758eb1d31/)
* [Sign in or Register | Stanford Lagunita](https://lagunita.stanford.edu/login?next=/courses/course-v1%3AEngineering%2BAlgorithms1%2BSelfPaced/courseware/e8eecbef0eef40bf9cd583f3599145e1/2103c3d12ce1427796f48d748da153b3/%3Factivate_block_id%3Dblock-v1%253AEngineering%252BAlgorithms1%252BSelfPaced%252Btype%2540sequential%252Bblock%25402103c3d12ce1427796f48d748da153b3)
* [Search results - Google Drive](https://drive.google.com/drive/search?q=owner:me%20(type:application/vnd.google.colaboratory%20||%20type:application/vnd.google.colab))
* [Assignment3.ipynb - Colaboratory](https://colab.research.google.com/drive/1yn-vwCYW0gcThxhWqe6vFxYLkiPQFGNl#scrollTo=Jm-lbZUfmhXF)
* [Aya-ZIbra/Stanford-Algorithm](https://github.com/Aya-ZIbra/Stanford-Algorithm)
* [Stanford-Algorithm/weekContents.md at master · Aya-ZIbra/Stanford-Algorithm](https://github.com/Aya-ZIbra/Stanford-Algorithm/blob/master/weekContents.md)
